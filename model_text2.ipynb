{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman\\AppData\\Local\\Temp\\ipykernel_14084\\1943918485.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = data['label_text'].apply(lambda x: 1 if x == 'informative' else 0)  # Map labels\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13608/13608 [00:00<00:00, 15636.58 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Aman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "comet_ml is installed but the Comet API Key is not configured. Please set the `COMET_API_KEY` environment variable to enable Comet logging. Check out the documentation for other ways of configuring it: https://www.comet.com/docs/v2/guides/experiment-management/configure-sdk/#set-the-api-key\n",
      "C:\\Users\\Aman\\AppData\\Local\\Temp\\ipykernel_14084\\1943918485.py:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  0%|          | 0/2553 [00:00<?, ?it/s]c:\\Users\\Aman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "                                                  \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 851/2553 [04:22<05:50,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27027004957199097, 'eval_accuracy': 0.8991769547325102, 'eval_runtime': 60.9455, 'eval_samples_per_second': 223.281, 'eval_steps_per_second': 13.963, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1000/2553 [04:57<06:03,  4.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3985, 'grad_norm': 1.2133082151412964, 'learning_rate': 3.0415197806502155e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1702/2553 [08:42<02:55,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1591004729270935, 'eval_accuracy': 0.9519400352733686, 'eval_runtime': 61.5156, 'eval_samples_per_second': 221.212, 'eval_steps_per_second': 13.834, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2000/2553 [09:52<02:08,  4.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2371, 'grad_norm': 5.294651508331299, 'learning_rate': 1.0830395613004309e-05, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2553/2553 [12:57<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09714954346418381, 'eval_accuracy': 0.974132863021752, 'eval_runtime': 58.0489, 'eval_samples_per_second': 234.423, 'eval_steps_per_second': 14.66, 'epoch': 3.0}\n",
      "{'train_runtime': 777.8227, 'train_samples_per_second': 52.485, 'train_steps_per_second': 3.282, 'train_loss': 0.2842159697087755, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 851/851 [00:57<00:00, 14.68it/s]\n",
      "C:\\Users\\Aman\\AppData\\Local\\Temp\\ipykernel_14084\\1943918485.py:92: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the training dataset\n",
    "train_file_path = 'crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_train.tsv'\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t')\n",
    "\n",
    "# Prepare data for Hugging Face Dataset\n",
    "def preprocess_text_data(data):\n",
    "    data = data[['tweet_text', 'label_text']]  # Select relevant columns\n",
    "    data['label'] = data['label_text'].apply(lambda x: 1 if x == 'informative' else 0)  # Map labels\n",
    "    return data\n",
    "\n",
    "train_data = preprocess_text_data(train_data)\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "hf_train = Dataset.from_pandas(train_data)\n",
    "\n",
    "# Define tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_data(batch):\n",
    "    return tokenizer(batch['tweet_text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "hf_train = hf_train.map(tokenize_data, batched=True)\n",
    "\n",
    "# Set dataset format for PyTorch\n",
    "hf_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# Define the model\n",
    "modeltext = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./modeltext\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",  # Do not save model checkpoints\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1000,\n",
    ")\n",
    "\n",
    "# Define compute_metrics function\n",
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=modeltext,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train,\n",
    "    eval_dataset=hf_train,  # Using training data for evaluation\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "predictions = trainer.predict(hf_train)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, preds, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=[\"non-informative\", \"informative\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to D:/BTP_2/CrisisMMD_v2.0/model_text\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory to save the model and tokenizer\n",
    "save_directory = \"D:/BTP_2/CrisisMMD_v2.0/model_text\"\n",
    "\n",
    "# Save the model\n",
    "modeltext.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
